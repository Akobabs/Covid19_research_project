{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cdd6557d",
   "metadata": {},
   "source": [
    "<h1 style=\"text-align:center;font-size:30px;\" > COVID-19 DETECTION USING CONCURRENT NEURAL NETWORK OPTIMIZED WITH COATI OPTIMIZER ALGORITHM </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb467919",
   "metadata": {},
   "source": [
    "# 1 OVERVIEW OF THE PROBLEM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a7ef707",
   "metadata": {},
   "source": [
    "## 1.1 Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a2309a",
   "metadata": {},
   "source": [
    "The COVID-19 pandemic, caused by the SARS-CoV-2 virus, has posed significant challenges to global health systems. Early and accurate detection of COVID-19 is crucial for effective patient management and controlling the spread of the virus. Traditional diagnostic methods, such as Reverse Transcription Polymerase Chain Reaction (RT-PCR), are time-consuming and require specialized laboratories. Therefore, there is a growing need for rapid, accurate, and scalable diagnostic tools.\n",
    "<ul>\n",
    "    <li> Early Diagnosis and Treatment </li> \n",
    "        Timely Intervention: Early detection of COVID-19 enables prompt medical intervention, which can significantly improve patient outcomes and reduce the severity of the disease. </li>\n",
    "        Preventing Complications: Identifying the virus early can help in preventing complications, especially in high-risk individuals such as the elderly and those with pre-existing conditions. </li>\n",
    "    <li> Containing the Spread </li>\n",
    "            Isolation and Quarantine: Detecting COVID-19 cases early allows for the immediate isolation of infected individuals, reducing the likelihood of transmission to others. </li>\n",
    "            Contact Tracing: Early detection aids in effective contact tracing, identifying and monitoring individuals who have been in close contact with an infected person. </li>\n",
    "    <li> Reducing Mortality Rates </li>\n",
    "            Improved Outcomes: Early and accurate detection can lead to better patient management, reducing the mortality rates associated with severe cases of COVID-19.\n",
    "            Preventing Overwhelm of Healthcare Systems: By controlling the spread and ensuring timely treatment, healthcare systems are less likely to be overwhelmed, which can help in maintaining the quality of care.</li>\n",
    "    <li> Economic Impact</li>\n",
    "            Reducing Economic Disruption: Early detection and containment can mitigate the economic impact of the pandemic by reducing the need for prolonged lockdowns and enabling quicker resumption of normal activities.\n",
    "            Workplace Safety: Regular screening in workplaces can help maintain a healthy workforce, ensuring business continuity and economic stability.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c62930b0",
   "metadata": {},
   "source": [
    "## 1.2 Business Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11bfd6f1",
   "metadata": {},
   "source": [
    "Developing a reliable and efficient system for the early detection of COVID-19 using advanced machine learning techniques, specifically Convolutional Neural Networks (CNNs) and the Coati Optimizer Algorithm. This system aims to address several critical needs:\n",
    "1. Accuracy and Speed in Diagnosis: </li>\n",
    "    Challenge: Traditional diagnostic methods like RT-PCR are accurate but time-consuming.\n",
    "    Solution: Implementing a CNN-based system can provide rapid and accurate diagnosis from medical images (e.g., chest X-rays or CT scans).\n",
    "\n",
    "2. Resource Optimization: </li>\n",
    "    Challenge: Limited healthcare resources need to be allocated effectively, especially during a pandemic.\n",
    "    Solution: Early and accurate detection can ensure that resources such as hospital beds, ventilators, and medical staff are used efficiently.\n",
    "\n",
    "3. Scalability and Accessibility: </li>\n",
    "    Challenge: Healthcare systems, especially in resource-limited settings, struggle to scale traditional diagnostic methods.\n",
    "    Solution: A machine learning-based detection system can be scaled to handle large volumes of data and can be deployed in various healthcare settings, including remote and underserved areas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "821d2ed0",
   "metadata": {},
   "source": [
    "## 1.3 Machine Learning Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4873575e",
   "metadata": {},
   "source": [
    "1. Feature Extraction and Classification: </li>\n",
    "    Task: Utilize CNNs to automatically extract relevant features from medical images and classify them as COVID-19 positive or negative.\n",
    "2. Optimization: </li>\n",
    "    Task: Apply the Coati Optimizer Algorithm to fine-tune the CNN model parameters for improved accuracy and performance.\n",
    "3. Handling Limited and Imbalanced Data: </li>\n",
    "    Task: Address challenges related to limited datasets and class imbalances to prevent model bias and ensure generalizability.\n",
    "4. Integration and Scalability: </li>\n",
    "    Task: Develop a system that can be integrated into existing healthcare workflows and scaled to handle large volumes of data.\n",
    "5. Bias Mitigation: </li>\n",
    "    Task: Ensure the model is fair and unbiased, providing accurate diagnoses across diverse patient populations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f93cbf1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Akoba\\AppData\\Local\\Temp\\ipykernel_11240\\3801991149.py:14: DeprecationWarning: `import kerastuner` is deprecated, please use `import keras_tuner`.\n",
      "  from kerastuner.tuners import RandomSearch\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing.image import DirectoryIterator\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import load_model\n",
    "import keras_tuner as kt\n",
    "from kerastuner.tuners import RandomSearch\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from typing import Tuple # Type hint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6554c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'C:/Users/Akoba/Desktop/START up/Covid19/Final COde'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "833bfbe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = path + '/LungData/train'\n",
    "val_dir = path + '/LungData/val'\n",
    "test_dir = path + '/LungData/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c18c48b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_generator = ImageDataGenerator(\n",
    "                                      rotation_range=20,\n",
    "                                      width_shift_range=0.1,\n",
    "                                      shear_range=0.1,\n",
    "                                      zoom_range=0.1,\n",
    "                                      samplewise_center=True,\n",
    "                                      samplewise_std_normalization=True\n",
    "                                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c240a6cf",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'C:/Users/Akoba/Desktop/START up/Covid19/Final COde/LungData/train'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_11240\\1871888317.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Create the training data generator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m train_generator = image_generator.flow_from_directory(\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mdirectory\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_dir\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mtarget_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m224\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m224\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# Resize images to 224x224 pixels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# Process 8 images per batch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\legacy\\preprocessing\\image.py\u001b[0m in \u001b[0;36mflow_from_directory\u001b[1;34m(self, directory, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, keep_aspect_ratio)\u001b[0m\n\u001b[0;32m   1136\u001b[0m         \u001b[0mkeep_aspect_ratio\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1137\u001b[0m     ):\n\u001b[1;32m-> 1138\u001b[1;33m         return DirectoryIterator(\n\u001b[0m\u001b[0;32m   1139\u001b[0m             \u001b[0mdirectory\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1140\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\legacy\\preprocessing\\image.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, keep_aspect_ratio, dtype)\u001b[0m\n\u001b[0;32m    451\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mclasses\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    452\u001b[0m             \u001b[0mclasses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 453\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0msubdir\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    454\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubdir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    455\u001b[0m                     \u001b[0mclasses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubdir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'C:/Users/Akoba/Desktop/START up/Covid19/Final COde/LungData/train'"
     ]
    }
   ],
   "source": [
    "# Create the training data generator\n",
    "train_generator = image_generator.flow_from_directory(\n",
    "    directory=train_dir,\n",
    "    target_size=(224, 224),  # Resize images to 224x224 pixels\n",
    "    batch_size=8,  # Process 8 images per batch\n",
    "    shuffle=True,  # Shuffle the order of images\n",
    "    class_mode='categorical'  # Multiple classes for classification\n",
    ")\n",
    "\n",
    "# Create the validation data generator\n",
    "validation_generator = image_generator.flow_from_directory(\n",
    "    directory=val_dir,\n",
    "    target_size=(224, 224),  # Resize images to 224x224 pixels\n",
    "    batch_size=1,  # Process 1 image per batch\n",
    "    shuffle=False,  # Do not shuffle the order of images\n",
    "    class_mode='categorical'  # Multiple classes for classification\n",
    ")\n",
    "\n",
    "# Create the test data generator\n",
    "test_generator = image_generator.flow_from_directory(\n",
    "    directory=test_dir,\n",
    "    target_size=(224, 224),  # Resize images to 224x224 pixels\n",
    "    batch_size=1,  # Process 1 image per batch\n",
    "    shuffle=False,  # Do not shuffle the order of images\n",
    "    class_mode='categorical'  # Multiple classes for classification\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d6c839",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_preprocessed_images(train: DirectoryIterator, num_images_per_class: int) -> None:\n",
    "    \"\"\"\n",
    "    Plots preprocessed images from each class in the training set.\n",
    "\n",
    "    Args:\n",
    "        train (DirectoryIterator): The training data iterator.\n",
    "        num_images_per_class (int): Number of preprocessed images to plot from each class.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # Initialize counters for each class\n",
    "    normal_count = 0\n",
    "    covid_count = 0\n",
    "\n",
    "    # Plot preprocessed images from each class\n",
    "    fig, axes = plt.subplots(2, num_images_per_class, figsize=(12, 6))\n",
    "\n",
    "    for images, labels in train:\n",
    "        for i in range(len(images)):\n",
    "            # Get the corresponding class label\n",
    "            class_label = labels[i]\n",
    "\n",
    "            # Plot the image based on the class label\n",
    "            if class_label[0] == 1:\n",
    "                if covid_count < num_images_per_class:\n",
    "                    axes[0, covid_count].imshow(images[i])\n",
    "                    axes[0, covid_count].set_title('COVID-19')\n",
    "                    axes[0, covid_count].axis('off')\n",
    "                    covid_count += 1\n",
    "            elif class_label[1] == 1:\n",
    "                if normal_count < num_images_per_class:\n",
    "                    axes[1, normal_count].imshow(images[i])\n",
    "                    axes[1, normal_count].set_title('NORMAL')\n",
    "                    axes[1, normal_count].axis('off')\n",
    "                    normal_count += 1\n",
    "\n",
    "        if normal_count >= num_images_per_class and covid_count >= num_images_per_class:\n",
    "            break\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1e9546",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_preprocessed_images(train=train_generator, num_images_per_class=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3aa0e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_image_and_histogram(image, label):\n",
    "    \"\"\"\n",
    "    Display a processed chest X-ray image and its pixel intensity histogram.\n",
    "\n",
    "    Args:\n",
    "        image (np.array): The processed chest X-ray image.\n",
    "        label (str): The label for the image.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    sns.set_style('white')\n",
    "\n",
    "    fig, axs = plt.subplots(2, 1, figsize=(8, 10))\n",
    "\n",
    "    # Display the image in the first subplot\n",
    "    axs[0].imshow(image, cmap='gray')\n",
    "    axs[0].set_title(f\"Processed Chest X-Ray Image: {label}\")\n",
    "    axs[0].axis('off')\n",
    "\n",
    "    # Display the histogram in the second subplot\n",
    "    sns.histplot(image.ravel(),\n",
    "                 label=f\"Mean: {np.mean(image):.4f}, Std Dev: {np.std(image):.4f}\",\n",
    "                 kde=False, ax=axs[1])\n",
    "    axs[1].legend(loc='upper center')\n",
    "    axs[1].set_title('Pixel Intensity Distribution')\n",
    "    axs[1].set_xlabel('Pixel Intensity')\n",
    "    axs[1].set_ylabel('Number of Pixels')\n",
    "\n",
    "    # Adjust layout\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "\n",
    "    # Print image details\n",
    "    print(f\"Image dimensions: {image.shape[0]} x {image.shape[1]} pixels, single color channel.\")\n",
    "    print(f\"Maximum pixel value: {image.max():.4f}\")\n",
    "    print(f\"Minimum pixel value: {image.min():.4f}\")\n",
    "    print(f\"Mean pixel value: {image.mean():.4f}\")\n",
    "    print(f\"Standard deviation of pixel values: {image.std():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70afd9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_image, label = train_generator.__getitem__(0)\n",
    "image = generated_image[0]\n",
    "label = label[0]\n",
    "display_image_and_histogram(image, label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e44ac3d2",
   "metadata": {},
   "source": [
    "<h1 style=\"text-align:center;font-size:30px;\" > MODELLING USING CONCURRENT NEURAL NETWORK OPTIMIZED WITH COATI OPTIMIZER ALGORITHM </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf12945",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'C:/Users/Akoba/Desktop/START up/Covid19/Final COde'\n",
    "train_dir = os.path.join(path + '/LungData/train')\n",
    "val_dir = os.path.join(path + '/LungData/val')\n",
    "test_dir = os.path.join(path + '/LungData/test')\n",
    "\n",
    "print(\"Train set:\\n____________________\")\n",
    "\n",
    "num_covid19_train = len(os.listdir(os.path.join(train_dir, 'COVID19')))\n",
    "num_normal_train = len(os.listdir(os.path.join(train_dir, 'NORMAL')))\n",
    "\n",
    "print(f\"COVID19 = {num_covid19_train}\")\n",
    "print(f\"NORMAL = {num_normal_train}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8a1619",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the total number of training samples\n",
    "total_samples = num_covid19_train + num_normal_train\n",
    "\n",
    "# Compute class weights to handle class imbalance\n",
    "class_weight_covid19 = total_samples / (3 * num_covid19_train)\n",
    "class_weight_normal = total_samples / (3 * num_normal_train)\n",
    "\n",
    "# Create a dictionary to store the class weights\n",
    "class_weights = {0: class_weight_covid19, 1: class_weight_normal}\n",
    "\n",
    "# Print out the calculated class weights\n",
    "print(f\"Weight for COVID-19 class (0): {class_weight_covid19:.2f}\")\n",
    "print(f\"Weight for NORMAL class (1): {class_weight_normal:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4016fc8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a03d42c8",
   "metadata": {},
   "source": [
    "# COATI OPTIMIZER ALGORITHM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71bef90b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Coati(tf.keras.optimizers.Optimizer):\n",
    "    def __init__(self, learning_rate=0.01, name='Coati', **kwargs):\n",
    "        \"\"\"Constructs a new Coati optimizer.\n",
    "\n",
    "        Args:\n",
    "            learning_rate: A Tensor or a floating point value. The learning rate.\n",
    "            name: Optional name prefix for the operations created when applying gradients.\n",
    "            **kwargs: Keyword arguments. Allowed to be one of \"clipnorm\" or \"clipvalue\".\n",
    "        \"\"\"\n",
    "        super(Coati, self).__init__(name, **kwargs)\n",
    "        self._set_hyper('learning_rate', kwargs.get('lr', learning_rate))  # handle lr=learning_rate\n",
    "        # Add any other hyperparameters you need here\n",
    "\n",
    "    def _create_slots(self, var_list):\n",
    "        # Create slots for additional tensors here\n",
    "        pass\n",
    "\n",
    "    def _resource_apply_dense(self, grad, var, apply_state=None):\n",
    "        # Update 'var' with 'grad' here using your custom optimization algorithm\n",
    "        lr_t = self._decayed_lr(tf.float32)  # handle learning rate decay\n",
    "        var.assign_sub(lr_t * grad)\n",
    "\n",
    "    def _resource_apply_sparse(self, grad, var, indices, apply_state=None):\n",
    "        # Handle sparse gradient updates here if necessary\n",
    "        lr_t = self._decayed_lr(tf.float32)  # handle learning rate decay\n",
    "        var.assign_sub(lr_t * tf.gather(grad, indices))\n",
    "\n",
    "    def get_config(self):\n",
    "        base_config = super(Coati, self).get_config()\n",
    "        return {**base_config, 'learning_rate': self._serialize_hyperparameter('learning_rate')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67eee1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    \"\"\"\n",
    "    Builds a convolutional neural network model with hyperparameter tuning, including the Coati optimizer.\n",
    "\n",
    "    Parameters:\n",
    "    - hp (kerastuner.HyperParameters): HyperParameters object for tuning the model.\n",
    "\n",
    "    Returns:\n",
    "    - keras.Sequential: The compiled model.\n",
    "    \"\"\"\n",
    "    model = keras.Sequential()\n",
    "\n",
    "    # Tune the number of convolutional layers\n",
    "    for i in range(hp.Int('num_conv_layers', min_value=1, max_value=4)):\n",
    "        model.add(layers.Conv2D(hp.Int(f'filters_{i}', min_value=32, max_value=256),\n",
    "                                kernel_size=hp.Choice(f'kernel_size_{i}', values=[3, 5]),\n",
    "                                activation='relu'))\n",
    "        model.add(layers.MaxPooling2D(pool_size=hp.Choice(f'pool_size_{i}', values=[2, 3])))\n",
    "\n",
    "    model.add(layers.Flatten())\n",
    "\n",
    "    # Tune the number of dense layers\n",
    "    for i in range(hp.Int('num_dense_layers', min_value=1, max_value=3)):\n",
    "        model.add(layers.Dense(units=hp.Int(f'num_units_{i}', min_value=64, max_value=512),\n",
    "                                activation='relu'))\n",
    "        # Tune the dropout rate\n",
    "        model.add(layers.Dropout(rate=hp.Float(f'dropout_rate_{i}', min_value=0.0, max_value=0.5)))\n",
    "\n",
    "    model.add(layers.Dense(2, activation='softmax'))  # 2 classes: COVID19 and NORMAL\n",
    "\n",
    "    # Tune the learning rate\n",
    "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "\n",
    "    # Include Coati optimizer in the hyperparameter choices\n",
    "    hp_optimizer = hp.Choice('optimizer', values=['adam', 'rmsprop', 'sgd', 'coati'])\n",
    "\n",
    "    if hp_optimizer == 'coati':\n",
    "        optimizer = Coati(learning_rate=hp_learning_rate)\n",
    "    else:\n",
    "        optimizer = keras.optimizers.get({\n",
    "            'class_name': hp_optimizer,\n",
    "            'config': {'learning_rate': hp_learning_rate}\n",
    "        })\n",
    "\n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7eb6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "# Set up the random search tuner\n",
    "tuner = RandomSearch(\n",
    "    hypermodel=build_model,  # Function that returns a compiled model\n",
    "    objective='val_accuracy',  # Objective metric to optimize\n",
    "    max_trials=2,  # Total number of trials to run\n",
    "    executions_per_trial=1,  # Number of model fits per trial\n",
    "    directory=os.path.join(path, 'tuner_directory'),  # Path to save logs and models\n",
    "    project_name='covid-19 classification'  # Tuning session name\n",
    ")\n",
    "\n",
    "# Initialize early stopping mechanism\n",
    "stop_early = EarlyStopping(monitor='val_loss', patience=10)  # Halt training when val_loss stops improving\n",
    "\n",
    "# Execute the search for optimal hyperparameters\n",
    "tuner.search(\n",
    "    x=train_generator,  # Training data generator\n",
    "    epochs=20,  # Number of epochs to train each model configuration\n",
    "    validation_data=validation_generator,  # Validation data generator\n",
    "    callbacks=[stop_early]  # List of callbacks to apply during training\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5b7e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Acquire the optimal hyperparameters\n",
    "optimal_hp = tuner.get_best_hyperparameters()[0]\n",
    "  # The get_best_hyperparameters() function retrieves a list of top hyperparameter sets.\n",
    "  # Selecting the first item [0] gives us the set with the best performance.\n",
    "\n",
    "# Display the optimal hyperparameters \n",
    "print(\"Optimal Hyperparameters:\")\n",
    "print(f\"- Convolutional Layers Count: {optimal_hp.get('num_conv_layers')}\")\n",
    "for layer_index in range(optimal_hp.get('num_conv_layers')):\n",
    "    print(f\"  - Conv Layer {layer_index+1} Filters: {optimal_hp.get(f'filters_{layer_index}')}\")\n",
    "    print(f\"  - Conv Layer {layer_index+1} Kernel Size: {optimal_hp.get(f'kernel_size_{layer_index}')}\")\n",
    "    print(f\"  - Conv Layer {layer_index+1} Pooling Size: {optimal_hp.get(f'pool_size_{layer_index}')}\")\n",
    "print(f\"- Dense Layers Count: {optimal_hp.get('num_dense_layers')}\")\n",
    "for layer_index in range(optimal_hp.get('num_dense_layers')):\n",
    "    print(f\"  - Dense Layer {layer_index+1} Units: {optimal_hp.get(f'num_units_{layer_index}')}\")\n",
    "    print(f\"  - Dense Layer {layer_index+1} Dropout: {optimal_hp.get(f'dropout_rate_{layer_index}')}\")\n",
    "print(f\"- Learning Rate: {optimal_hp.get('learning_rate')}\")\n",
    "# Ensure to include 'Coati' if it's the selected optimizer\n",
    "optimizer = optimal_hp.get('optimizer')\n",
    "print(f\"- Optimizer: {'Coati' if optimizer == 'Coati' else optimizer}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13729ee7",
   "metadata": {},
   "source": [
    "### Best Hyperparameter Ecample would look like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec3e3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_model():\n",
    "    model = keras.Sequential()\n",
    "    input_shape = (224, 224, 3)\n",
    "    \n",
    "    # Convolutional layers\n",
    "    model.add(layers.Conv2D(156, kernel_size=3, activation='relu', input_shape=(input_shape)))\n",
    "    model.add(layers.MaxPooling2D(pool_size=2))\n",
    "    model.add(layers.Conv2D(149, kernel_size=3, activation='relu'))\n",
    "    model.add(layers.MaxPooling2D(pool_size=2))\n",
    "    model.add(layers.Conv2D(192, kernel_size=3, activation='relu'))\n",
    "    model.add(layers.MaxPooling2D(pool_size=3))\n",
    "    model.add(layers.Conv2D(254, kernel_size=5, activation='relu'))\n",
    "    model.add(layers.MaxPooling2D(pool_size=2))\n",
    "\n",
    "    model.add(layers.Flatten())\n",
    "\n",
    "    # Dense layers\n",
    "    model.add(layers.Dense(188, activation='relu'))\n",
    "    model.add(layers.Dropout(0.4296478261801449))\n",
    "    model.add(layers.Dense(310, activation='relu'))\n",
    "    model.add(layers.Dropout(0.20158293434446))\n",
    "    model.add(layers.Dense(2, activation='softmax'))  # 3 classes: COVID19 andNORMAL\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.01), \n",
    "                  loss='categorical_crossentropy', # categorical_crossentropy loss function porque es Multi-class\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "# Create the model\n",
    "best_model = best_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b46b8929",
   "metadata": {},
   "source": [
    "# MODEL TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "082f1f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assemble the model using the optimal hyperparameters\n",
    "model = tuner.hypermodel.build(optimal_hp)\n",
    "\n",
    "# Initialize early stopping mechanism\n",
    "stop_early = EarlyStopping(monitor='val_loss', patience=5)  # Halt training when val_loss stops improving\n",
    "\n",
    "# Commence training of the top-performing model\n",
    "training_process = model.fit(train_generator, \n",
    "                                         epochs=20,\n",
    "                                         batch_size=32,\n",
    "                                         validation_data=validation_generator, \n",
    "                                         class_weight=class_weights\n",
    "                                        )\n",
    "\n",
    "# Persisting the model post-training\n",
    "model.save(os.path.join(path, 'models', 'model_cnn_coati.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d546b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the weights\n",
    "model.save_weights('C:/Users/Akoba/Desktop/START up/Covid19/Final COde/models/model_weights.weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596b36bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To save the model once it has been trained \n",
    "model.save('C:/Users/Akoba/Desktop/START up/Covid19/Final COde/models/model_covid_classif.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6346b5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77ead96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the most suitable number of epochs for model training using the acquired hyperparameters.\n",
    "validation_accuracy_each_epoch = training_process.history['val_accuracy']\n",
    "optimal_epoch = validation_accuracy_each_epoch.index(max(validation_accuracy_each_epoch)) + 1\n",
    "print('Optimal epoch for training: %d' % (optimal_epoch,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4a4fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(training_process.history['accuracy'])\n",
    "plt.plot(training_process.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fbe4999",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(training_process.history['loss'])\n",
    "plt.plot(training_process.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0043bb72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the best model on the test set\n",
    "evaluation = model.evaluate(test_generator)\n",
    "print(f\"Test Accuracy: {evaluation[1] * 100:.2f}%\")\n",
    "\n",
    "evaluation = model.evaluate(train_generator)\n",
    "print(f\"Train Accuracy: {evaluation[1] * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293714ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = model.predict(test_generator) # y_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5c5089",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted # predicted.shape: (****, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c49e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'np.argmax(p)' retrieves the index of the highest value in 'p', which aligns with the class that the model's softmax output deems most probable.\n",
    "predicted_classes = [np.argmax(probability) for probability in predicted] # holds the predicted classes for each sample in the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a97b626",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve actual class labels\n",
    "actual_classes = test_generator.classes # Example output: array([0, 0, 0, ..., 1, 1, 1], dtype=int32)\n",
    "\n",
    "# Generate the confusion matrix\n",
    "conf_matrix = confusion_matrix(actual_classes, predicted_classes)\n",
    "\n",
    "# Visualize the confusion matrix\n",
    "plt.figure(figsize=(5, 4))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('Actual Label')\n",
    "plt.title('Confusion Matrix Display')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd0f68ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_names = ['Class 0: COVID19', 'Class 1: NORMAL']\n",
    "print(classification_report(actual_classes, predicted_classes, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee826ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "new_model = tf.keras.models.load_model('C:/Users/Akoba/Desktop/START up/Covid19/Final COde/models/model_covid_classif.h5')\n",
    "# Check its architecture\n",
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13875f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming binary classification and 'predicted_probabilities' is a 2D array with shape (n_samples, n_classes)\n",
    "# where each column is the probability for each class.\n",
    "# We take the probabilities for the positive class (usually class 1)\n",
    "positive_class_probabilities = predicted_probabilities[:, 1]\n",
    "\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr, tpr, _ = roc_curve(actual_classes, positive_class_probabilities)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "011daf49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming the training history is stored in a variable named 'history'\n",
    "# Example: history = model.fit(...)\n",
    "\n",
    "# Plotting accuracy\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(training_process.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(training_process.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# Plotting loss\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(training_process.history['loss'], label='Training Loss')\n",
    "plt.plot(training_process.history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9eee3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new figure\n",
    "fig, ax1 = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "# Plot accuracy on the first y-axis\n",
    "ax1.plot(training_process.history['accuracy'], label='Training Accuracy', color='red', linestyle='dashed')\n",
    "ax1.plot(training_process.history['val_accuracy'], label='Validation Accuracy', color='blue', linestyle='dashed')\n",
    "ax1.set_xlabel('Epochs')\n",
    "ax1.set_ylabel('Accuracy', color='blue')\n",
    "ax1.tick_params(axis='y', labelcolor='red')\n",
    "\n",
    "# Create a second y-axis to plot loss\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(training_process.history['loss'], label='Training Loss', color='red')\n",
    "ax2.plot(training_process.history['val_loss'], label='Validation Loss', color='blue')\n",
    "ax2.set_ylabel('Loss', color='blue')\n",
    "ax2.tick_params(axis='y', labelcolor='red')\n",
    "\n",
    "# Add legends\n",
    "fig.tight_layout()\n",
    "ax1.legend(loc='upper left')\n",
    "ax2.legend(loc='upper right')\n",
    "\n",
    "plt.title('Training and Validation Accuracy and Loss')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33dc391b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
